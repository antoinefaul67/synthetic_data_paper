{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d650e6-96d8-4b4c-8c34-5f28ac9e5abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : \n",
      "    The default C++ compiler could not be found on your system.\n",
      "    You need to either define the CXX environment variable or a symlink to the g++ command.\n",
      "    For example if g++-8 is the command you can do\n",
      "      import os\n",
      "      os.environ['CXX'] = 'g++-8'\n",
      "    \n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyreadr\n",
    "import random\n",
    "import gower\n",
    "import sdv.metadata.single_table as m\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "import numpy as np\n",
    "from synthcity.metrics.eval_detection import DetectionEvaluator, SyntheticDetectionXGB\n",
    "from synthcity.metrics.eval_privacy import IdentifiabilityScore, kAnonymization,  lDiversityDistinct\n",
    "from synthcity.metrics.eval_attacks import AttackEvaluator\n",
    "from sdmetrics.single_table import DCRBaselineProtection\n",
    "from synthcity.metrics.eval_statistical import  MaximumMeanDiscrepancy, WassersteinDistance, AlphaPrecision, PRDCScore, InverseKLDivergence, JensenShannonDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c289b0ee-ece7-4c2f-8a34-34bcb3cd4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(31125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c6486b2-0b68-4c9b-af4c-43ee84f0c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/antoi/Downloads/synthetic_data_paper-main/synthetic_data_paper-main\")\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca5543d-3f1b-4d2a-aa08-550b208c31c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(current_directory, \"data\")\n",
    "\n",
    "\n",
    "dataset = \"menobalance\"\n",
    "# Read the CSV file\n",
    "\n",
    "if dataset == \"menobalance\":\n",
    "   df = pd.read_csv(data_path + \"\\\\menobalance_data.csv\")\n",
    "   df = df.iloc[:,[0,1,2,3,4,5,6]]\n",
    "   loader = GenericDataLoader(df)\n",
    "   # Convert to meta table for Python use\n",
    "   metadata = m.SingleTableMetadata()\n",
    "   metadata.detect_from_dataframe(df)\n",
    "   discrete_columns = [\"Smoker\",\"Diabetes\"]\n",
    "   binary_idx = [1,5]\n",
    "   current_directory = os.path.join(current_directory, \"menobalance\")\n",
    "if dataset == \"wisconsin\":\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df = df.iloc[:,[14,26,28,29]]\n",
    "    df.columns = [\"14\",\"26\",\"28\",\"29\"]\n",
    "    loader = GenericDataLoader(df)\n",
    "    discrete_columns = []\n",
    "    binary_idx = []\n",
    "   # Convert to meta table for Python use\n",
    "    metadata = m.SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "    current_directory = os.path.join(current_directory, \"wisconsin\")\n",
    "if dataset == \"cleveland\":\n",
    "    url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    df = df.iloc[:,[3,7,4,0]]\n",
    "    df.columns = [\"3\",\"7\",\"4\",\"0\"]\n",
    "    discrete_columns = []\n",
    "    loader = GenericDataLoader(df)\n",
    "    binary_idx = []\n",
    "    # Convert to meta table for Python use\n",
    "    metadata = m.SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)\n",
    "    current_directory = os.path.join(current_directory, \"cleveland\")\n",
    "if dataset == \"simulated_gmcm\": \n",
    "    simulated_path = \"C:/Users/antoi/Documents/UNIBE/Synthetic data generation/results_paper/\"\n",
    "    df = pd.read_csv(data_path + \"simulated_GMCM_data.csv\")\n",
    "    df = df.iloc[:,[1,2]]\n",
    "    discrete_columns = []\n",
    "    df.columns = [\"X1\",\"X2\"]\n",
    "    binary_idx = []\n",
    "    current_directory = os.path.join(current_directory, \"simulated_gmcm\")\n",
    "    loader = GenericDataLoader(df)\n",
    "    # Convert to meta table for Python use\n",
    "    metadata = m.SingleTableMetadata()\n",
    "    metadata.detect_from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e60ad8b3-6d49-4799-96e7-6de831849b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_pairwise_distances(X, binary_idx):\n",
    "    \"\"\"\n",
    "    Computes a vector of median distances per dimension between all pairs of points.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.ndarray): shape (n_samples, d), input data.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: shape (d,), median per-dimension pairwise distances.\n",
    "    \"\"\"\n",
    "    n_samples, d = X.shape\n",
    "    medians = np.zeros(d)\n",
    "    for k in range(d):\n",
    "        if k in binary_idx:\n",
    "            medians[k] = 1.0\n",
    "        else:\n",
    "            col = X[:, k]\n",
    "            # Compute absolute difference matrix for this column\n",
    "            diffs = np.abs(col[:, None] - col[None, :])\n",
    "            # Extract upper triangle (i < j)\n",
    "            triu_indices = np.triu_indices(n_samples, k=1)\n",
    "            dist_values = diffs[triu_indices]\n",
    "            medians[k] = np.median(dist_values)\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a43e519-6efe-4338-abb1-976d212de177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_rbf(X, Y, lengthscales):\n",
    "    \"\"\"\n",
    "    Compute pairwise anisotropic RBF kernel matrix between X and Y.\n",
    "    X: (n_x, d), Y: (n_y, d), lengthscales: (d,)\n",
    "    Returns kernel matrix (n_x, n_y)\n",
    "    \"\"\"\n",
    "    X = X / lengthscales\n",
    "    Y = Y / lengthscales\n",
    "    # ||x-y||^2 = ||x||^2 + ||y||^2 - 2x.y\n",
    "    X2 = np.sum(X**2, 1)[:, None]\n",
    "    Y2 = np.sum(Y**2, 1)[None, :]\n",
    "    dist2 = X2 + Y2 - 2 * np.dot(X, Y.T)\n",
    "    K = np.exp(-0.5 * dist2)\n",
    "    return K\n",
    "    \n",
    "def anisotropic_kernel(X, Y, bandwidths):\n",
    "    X_exp = X[:, None, :]\n",
    "    Y_exp = Y[None, :, :]\n",
    "    sq_diff = ((X_exp - Y_exp) ** 2) / (2 * bandwidths**2)\n",
    "    K = np.exp(-np.sum(sq_diff, axis=2))\n",
    "    return K\n",
    "\n",
    "def mmd2_unbiased(X, Y,binary_idx, lengthscales=None):\n",
    "    \"\"\"\n",
    "    Unbiased estimator for MMD^2 between X (n,d) and Y (m,d)\n",
    "    Optionally supply lengthscales (d,) or will compute medians.\n",
    "    \"\"\"\n",
    "    if lengthscales is None:\n",
    "        lengthscales = median_pairwise_distances(X,binary_idx)\n",
    "    n = X.shape[0]\n",
    "    m = Y.shape[0]\n",
    "\n",
    "    K_xx = anisotropic_rbf(X, X, lengthscales)\n",
    "    #np.fill_diagonal(K_xx, 0)\n",
    "    K_yy = anisotropic_rbf(Y, Y, lengthscales)\n",
    "    #np.fill_diagonal(K_yy, 0)\n",
    "    K_xy = anisotropic_rbf(X, Y, lengthscales)\n",
    "\n",
    "    mmd2 = (K_xx.sum() / (n*(n))\n",
    "           + K_yy.sum() / (m*(m))\n",
    "           - 2 * K_xy.sum() / (n*m))\n",
    "    return mmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b495f455-3c3b-4d7a-b6c2-cc0dc26e7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_files(folder_path, inputs, loader, discrete_columns, colnames, binary_idx,metadata_dict):\n",
    "    #loader = GenericDataLoader(pd.DataFrame(df))\n",
    "    dataframes = {input_name: [] for input_name in inputs}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df_synthetic = pd.read_csv(file_path)\n",
    "        elif file_name.endswith('.rds'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df_synthetic =  pyreadr.read_r(file_path)\n",
    "            df_synthetic = pd.DataFrame(df_synthetic[None])\n",
    "        for column in discrete_columns:\n",
    "            df_synthetic[column] = pd.to_numeric(df_synthetic[column])\n",
    "        df_synthetic.columns = colnames\n",
    "        synthetic_loader = GenericDataLoader(df_synthetic)\n",
    "            \n",
    "            # Example computations for each input\n",
    "        for input_name in inputs:\n",
    "            if input_name == 'MMD_aniso':\n",
    "                #computed_value = MMD.evaluate(loader,synthetic_loader)[\"joint\"]\n",
    "                computed_value = mmd2_unbiased(df.to_numpy(),df_synthetic.to_numpy(), binary_idx)\n",
    "            elif input_name == \"MMD\":\n",
    "                computed_value = MMD.evaluate(loader,synthetic_loader)[\"joint\"]\n",
    "            elif input_name == 'Wasserstein':\n",
    "                # Compute something different for input2, e.g., sum\n",
    "                computed_value = Wasserstein.evaluate(loader,synthetic_loader)[\"joint\"]\n",
    "            elif input_name == 'IKL':\n",
    "                # Compute something different for input2, e.g., sum\n",
    "                computed_value = IKL.evaluate(loader,synthetic_loader)[\"marginal\"]\n",
    "            elif input_name == 'JSD':\n",
    "                # Compute something different for input2, e.g., sum\n",
    "                computed_value = JSD.evaluate(loader,synthetic_loader)[\"marginal\"]\n",
    "            elif input_name == 'P-PR':\n",
    "                # Add more conditions as needed\n",
    "                computed_value = PRDC.evaluate(loader,synthetic_loader)[\"precision\"]\n",
    "            elif input_name == 'P-RE':\n",
    "                computed_value = PRDC.evaluate(loader,synthetic_loader)[\"recall\"]\n",
    "            elif input_name == 'density':\n",
    "                computed_value = PRDC.evaluate(loader,synthetic_loader)[\"density\"]\n",
    "            elif input_name == 'coverage':\n",
    "                computed_value =  PRDC.evaluate(loader,synthetic_loader)[\"coverage\"]\n",
    "            elif input_name == 'kAnonym':\n",
    "                computed_value =  kAnonym.evaluate(loader,synthetic_loader)[\"syn\"]\n",
    "            elif input_name == 'lDiversity':\n",
    "                computed_value =  lDiversity.evaluate(loader,synthetic_loader)[\"syn\"]\n",
    "            elif input_name == \"xgbDetection\":\n",
    "                computed_value =  xgb_detection.evaluate(loader,synthetic_loader)[\"mean\"]\n",
    "            elif  input_name == \"identifiability\":\n",
    "                computed_value =  identifiability.evaluate(loader,synthetic_loader)[\"score\"]\n",
    "            elif input_name ==\"DCRsdv\":\n",
    "                computed_value  = DCRBaselineProtection.compute_breakdown(real_data=df,synthetic_data=df_synthetic,metadata = metadata_dict)[\"score\"]  \n",
    "            elif input_name == \"DCR\":\n",
    "                distances = gower.gower_matrix(df_synthetic, df)\n",
    "                min_distances = distances.min(axis=1)\n",
    "                #computed_value = np.mean(min_distances)\n",
    "                computed_value = np.quantile(a=min_distances,q=0.05)\n",
    "            dataframes[input_name].append(computed_value)\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e181253d-d030-4523-8992-279da5e3a1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = [\"P-PR\",\"P-RE\",\"MMD\",\"IKL\",\"JSD\",\"DCR\",\"MMD_aniso\",\"DCRsdv\"]\n",
    "alpha = AlphaPrecision()\n",
    "detection_evaluator =  DetectionEvaluator()\n",
    "xgb_detection = SyntheticDetectionXGB()\n",
    "identifiability = IdentifiabilityScore()\n",
    "kAnonym = kAnonymization()\n",
    "lDiversity = lDiversityDistinct()\n",
    "MMD = MaximumMeanDiscrepancy()\n",
    "Wasserstein = WassersteinDistance()\n",
    "PRDC =  PRDCScore()\n",
    "\n",
    "IKL = InverseKLDivergence()\n",
    "JSD =  JensenShannonDistance()\n",
    "metadata_dict = metadata.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0927b159-c454-43b9-9dda-4c3c4ce05127",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a139558-ece9-4142-b527-2781b59b7530",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_names = [\n",
    "    \"GC_synthetizer\",\n",
    "    \"CTGAN synthetizer\",\n",
    "    \"GMCM\",\n",
    "    \"marginals\",\n",
    "    \"ARF\",\n",
    "    \"Vines\"\n",
    "    # Add more folder names as needed\n",
    "]\n",
    "results = {}\n",
    "\n",
    "colnames = df.columns\n",
    "\n",
    "# Process each folder\n",
    "for folder_name in folder_names:\n",
    "    folder_path = os.path.join(base_path, folder_name)\n",
    "    # Extract result name from the folder name\n",
    "    result_name = folder_name.split(' ')[0].replace(' ', '_')\n",
    "    # Process files in the folder\n",
    "    results[result_name] = process_csv_files(folder_path = folder_path, inputs = inputs, loader=loader, discrete_columns = discrete_columns, \n",
    "                                             colnames=colnames, binary_idx =  binary_idx, metadata_dict = metadata_dict)  # Replace \"inputs\" with actual variable\n",
    "\n",
    "# Convert results into DataFrames and calculate means\n",
    "means = {}\n",
    "standard_deviations = {}\n",
    "for result_name, result_data in results.items():\n",
    "    df1 = pd.DataFrame(result_data)\n",
    "    means[result_name] = df1.mean().to_dict()\n",
    "    standard_deviations[result_name] = df1.std().to_dict()\n",
    "\n",
    "# Construct the results DataFrame\n",
    "df_results = pd.DataFrame(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2a39d-4617-45ee-8652-73fd8a9107b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f3568-f5c2-4eb0-8e6c-1dab22d59a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std =  pd.DataFrame(standard_deviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c729f6-7298-4329-936f-cf047d91e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315423d-f5fe-4d67-bdc0-e6c4f80bf90c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
